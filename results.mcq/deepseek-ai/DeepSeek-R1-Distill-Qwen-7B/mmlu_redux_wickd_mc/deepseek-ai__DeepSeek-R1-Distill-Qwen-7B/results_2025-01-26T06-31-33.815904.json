{
  "results": {
    "mmlu_redux": {
      "alias": "mmlu_redux"
    },
    "mmlu_redux_anatomy": {
      "alias": " - anatomy",
      "acc,none": 0.38,
      "acc_stderr,none": 0.04878317312145634
    },
    "mmlu_redux_astronomy": {
      "alias": " - astronomy",
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562428
    },
    "mmlu_redux_business_ethics": {
      "alias": " - business_ethics",
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562428
    },
    "mmlu_redux_clinical_knowledge": {
      "alias": " - clinical_knowledge",
      "acc,none": 0.47,
      "acc_stderr,none": 0.050161355804659205
    },
    "mmlu_redux_college_chemistry": {
      "alias": " - college_chemistry",
      "acc,none": 0.36,
      "acc_stderr,none": 0.048241815132442176
    },
    "mmlu_redux_college_computer_science": {
      "alias": " - college_computer_science",
      "acc,none": 0.57,
      "acc_stderr,none": 0.04975698519562428
    },
    "mmlu_redux_college_mathematics": {
      "alias": " - college_mathematics",
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795
    },
    "mmlu_redux_college_medicine": {
      "alias": " - college_medicine",
      "acc,none": 0.44,
      "acc_stderr,none": 0.04988876515698589
    },
    "mmlu_redux_college_physics": {
      "alias": " - college_physics",
      "acc,none": 0.4,
      "acc_stderr,none": 0.049236596391733084
    },
    "mmlu_redux_conceptual_physics": {
      "alias": " - conceptual_physics",
      "acc,none": 0.57,
      "acc_stderr,none": 0.049756985195624284
    },
    "mmlu_redux_econometrics": {
      "alias": " - econometrics",
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605
    },
    "mmlu_redux_electrical_engineering": {
      "alias": " - electrical_engineering",
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912
    },
    "mmlu_redux_formal_logic": {
      "alias": " - formal_logic",
      "acc,none": 0.47,
      "acc_stderr,none": 0.05016135580465919
    },
    "mmlu_redux_global_facts": {
      "alias": " - global_facts",
      "acc,none": 0.27,
      "acc_stderr,none": 0.04461960433384739
    },
    "mmlu_redux_high_school_chemistry": {
      "alias": " - high_school_chemistry",
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795
    },
    "mmlu_redux_high_school_geography": {
      "alias": " - high_school_geography",
      "acc,none": 0.48,
      "acc_stderr,none": 0.050211673156867795
    },
    "mmlu_redux_high_school_macroeconomics": {
      "alias": " - high_school_macroeconomics",
      "acc,none": 0.44,
      "acc_stderr,none": 0.049888765156985884
    },
    "mmlu_redux_high_school_mathematics": {
      "alias": " - high_school_mathematics",
      "acc,none": 0.42,
      "acc_stderr,none": 0.049604496374885836
    },
    "mmlu_redux_high_school_physics": {
      "alias": " - high_school_physics",
      "acc,none": 0.5,
      "acc_stderr,none": 0.050251890762960605
    },
    "mmlu_redux_high_school_statistics": {
      "alias": " - high_school_statistics",
      "acc,none": 0.6,
      "acc_stderr,none": 0.04923659639173309
    },
    "mmlu_redux_high_school_us_history": {
      "alias": " - high_school_us_history",
      "acc,none": 0.62,
      "acc_stderr,none": 0.048783173121456316
    },
    "mmlu_redux_human_aging": {
      "alias": " - human_aging",
      "acc,none": 0.55,
      "acc_stderr,none": 0.05
    },
    "mmlu_redux_logical_fallacies": {
      "alias": " - logical_fallacies",
      "acc,none": 0.63,
      "acc_stderr,none": 0.04852365870939099
    },
    "mmlu_redux_machine_learning": {
      "alias": " - machine_learning",
      "acc,none": 0.46,
      "acc_stderr,none": 0.05009082659620332
    },
    "mmlu_redux_miscellaneous": {
      "alias": " - miscellaneous",
      "acc,none": 0.51,
      "acc_stderr,none": 0.05024183937956912
    },
    "mmlu_redux_philosophy": {
      "alias": " - philosophy",
      "acc,none": 0.54,
      "acc_stderr,none": 0.05009082659620332
    },
    "mmlu_redux_professional_accounting": {
      "alias": " - professional_accounting",
      "acc,none": 0.4,
      "acc_stderr,none": 0.04923659639173309
    },
    "mmlu_redux_professional_law": {
      "alias": " - professional_law",
      "acc,none": 0.21,
      "acc_stderr,none": 0.040936018074033256
    },
    "mmlu_redux_public_relations": {
      "alias": " - public_relations",
      "acc,none": 0.52,
      "acc_stderr,none": 0.050211673156867795
    },
    "mmlu_redux_virology": {
      "alias": " - virology",
      "acc,none": 0.34,
      "acc_stderr,none": 0.04760952285695236
    }
  },
  "groups": {
    "mmlu_redux": {
      "alias": "mmlu_redux"
    }
  },
  "group_subtasks": {
    "mmlu_redux": [
      "mmlu_redux_machine_learning",
      "mmlu_redux_professional_law",
      "mmlu_redux_logical_fallacies",
      "mmlu_redux_high_school_macroeconomics",
      "mmlu_redux_conceptual_physics",
      "mmlu_redux_human_aging",
      "mmlu_redux_philosophy",
      "mmlu_redux_virology",
      "mmlu_redux_clinical_knowledge",
      "mmlu_redux_college_chemistry",
      "mmlu_redux_astronomy",
      "mmlu_redux_public_relations",
      "mmlu_redux_miscellaneous",
      "mmlu_redux_college_medicine",
      "mmlu_redux_high_school_mathematics",
      "mmlu_redux_high_school_physics",
      "mmlu_redux_anatomy",
      "mmlu_redux_global_facts",
      "mmlu_redux_high_school_statistics",
      "mmlu_redux_high_school_us_history",
      "mmlu_redux_high_school_chemistry",
      "mmlu_redux_college_computer_science",
      "mmlu_redux_econometrics",
      "mmlu_redux_high_school_geography",
      "mmlu_redux_professional_accounting",
      "mmlu_redux_business_ethics",
      "mmlu_redux_formal_logic",
      "mmlu_redux_college_mathematics",
      "mmlu_redux_electrical_engineering",
      "mmlu_redux_college_physics"
    ]
  },
  "configs": {
    "mmlu_redux_anatomy": {
      "task": "mmlu_redux_anatomy",
      "task_alias": "anatomy",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "anatomy",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_astronomy": {
      "task": "mmlu_redux_astronomy",
      "task_alias": "astronomy",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "astronomy",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_business_ethics": {
      "task": "mmlu_redux_business_ethics",
      "task_alias": "business_ethics",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "business_ethics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_clinical_knowledge": {
      "task": "mmlu_redux_clinical_knowledge",
      "task_alias": "clinical_knowledge",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "clinical_knowledge",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_college_chemistry": {
      "task": "mmlu_redux_college_chemistry",
      "task_alias": "college_chemistry",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "college_chemistry",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_college_computer_science": {
      "task": "mmlu_redux_college_computer_science",
      "task_alias": "college_computer_science",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "college_computer_science",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_college_mathematics": {
      "task": "mmlu_redux_college_mathematics",
      "task_alias": "college_mathematics",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "college_mathematics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_college_medicine": {
      "task": "mmlu_redux_college_medicine",
      "task_alias": "college_medicine",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "college_medicine",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_college_physics": {
      "task": "mmlu_redux_college_physics",
      "task_alias": "college_physics",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "college_physics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_conceptual_physics": {
      "task": "mmlu_redux_conceptual_physics",
      "task_alias": "conceptual_physics",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "conceptual_physics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_econometrics": {
      "task": "mmlu_redux_econometrics",
      "task_alias": "econometrics",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "econometrics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_electrical_engineering": {
      "task": "mmlu_redux_electrical_engineering",
      "task_alias": "electrical_engineering",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "electrical_engineering",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_formal_logic": {
      "task": "mmlu_redux_formal_logic",
      "task_alias": "formal_logic",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "formal_logic",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_global_facts": {
      "task": "mmlu_redux_global_facts",
      "task_alias": "global_facts",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "global_facts",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_high_school_chemistry": {
      "task": "mmlu_redux_high_school_chemistry",
      "task_alias": "high_school_chemistry",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "high_school_chemistry",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_high_school_geography": {
      "task": "mmlu_redux_high_school_geography",
      "task_alias": "high_school_geography",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "high_school_geography",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_high_school_macroeconomics": {
      "task": "mmlu_redux_high_school_macroeconomics",
      "task_alias": "high_school_macroeconomics",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "high_school_macroeconomics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_high_school_mathematics": {
      "task": "mmlu_redux_high_school_mathematics",
      "task_alias": "high_school_mathematics",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "high_school_mathematics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_high_school_physics": {
      "task": "mmlu_redux_high_school_physics",
      "task_alias": "high_school_physics",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "high_school_physics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_high_school_statistics": {
      "task": "mmlu_redux_high_school_statistics",
      "task_alias": "high_school_statistics",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "high_school_statistics",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_high_school_us_history": {
      "task": "mmlu_redux_high_school_us_history",
      "task_alias": "high_school_us_history",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "high_school_us_history",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_human_aging": {
      "task": "mmlu_redux_human_aging",
      "task_alias": "human_aging",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "human_aging",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_logical_fallacies": {
      "task": "mmlu_redux_logical_fallacies",
      "task_alias": "logical_fallacies",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "logical_fallacies",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_machine_learning": {
      "task": "mmlu_redux_machine_learning",
      "task_alias": "machine_learning",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "machine_learning",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_miscellaneous": {
      "task": "mmlu_redux_miscellaneous",
      "task_alias": "miscellaneous",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "miscellaneous",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_philosophy": {
      "task": "mmlu_redux_philosophy",
      "task_alias": "philosophy",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "philosophy",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_professional_accounting": {
      "task": "mmlu_redux_professional_accounting",
      "task_alias": "professional_accounting",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "professional_accounting",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_professional_law": {
      "task": "mmlu_redux_professional_law",
      "task_alias": "professional_law",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "professional_law",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_public_relations": {
      "task": "mmlu_redux_public_relations",
      "task_alias": "public_relations",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "public_relations",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mmlu_redux_virology": {
      "task": "mmlu_redux_virology",
      "task_alias": "virology",
      "dataset_path": "edinburgh-dawg/mmlu-redux",
      "dataset_name": "virology",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "test_split": "test",
      "fewshot_split": "test",
      "process_docs": "def preprocessing(dataset):\n    \n    def process_doc(doc):\n        \n        original_doc = copy.copy(doc)\n        if can_be_flipped(doc['question']):\n            # randomly select an answer to hide:\n            answer_to_hide = random.choice(doc['choices'])        \n            doc['choices'].remove(answer_to_hide)\n            doc['choices'].append(\"None of the above\")\n            correct_answer = original_doc['choices'][original_doc['answer']]\n            if correct_answer not in doc['choices']:\n                correct_answer = \"None of the above\"\n            \n            doc['answer'] = doc['choices'].index(correct_answer)\n        return doc\n        \n    return dataset.map(process_doc)\n",
      "doc_to_text": "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:",
      "doc_to_target": "answer",
      "doc_to_choice": [
        "A",
        "B",
        "C",
        "D"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "fewshot_config": {
        "sampler": "first_n"
      },
      "num_fewshot": 5,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    }
  },
  "versions": {
    "mmlu_redux": 2.0,
    "mmlu_redux_anatomy": 1.0,
    "mmlu_redux_astronomy": 1.0,
    "mmlu_redux_business_ethics": 1.0,
    "mmlu_redux_clinical_knowledge": 1.0,
    "mmlu_redux_college_chemistry": 1.0,
    "mmlu_redux_college_computer_science": 1.0,
    "mmlu_redux_college_mathematics": 1.0,
    "mmlu_redux_college_medicine": 1.0,
    "mmlu_redux_college_physics": 1.0,
    "mmlu_redux_conceptual_physics": 1.0,
    "mmlu_redux_econometrics": 1.0,
    "mmlu_redux_electrical_engineering": 1.0,
    "mmlu_redux_formal_logic": 1.0,
    "mmlu_redux_global_facts": 1.0,
    "mmlu_redux_high_school_chemistry": 1.0,
    "mmlu_redux_high_school_geography": 1.0,
    "mmlu_redux_high_school_macroeconomics": 1.0,
    "mmlu_redux_high_school_mathematics": 1.0,
    "mmlu_redux_high_school_physics": 1.0,
    "mmlu_redux_high_school_statistics": 1.0,
    "mmlu_redux_high_school_us_history": 1.0,
    "mmlu_redux_human_aging": 1.0,
    "mmlu_redux_logical_fallacies": 1.0,
    "mmlu_redux_machine_learning": 1.0,
    "mmlu_redux_miscellaneous": 1.0,
    "mmlu_redux_philosophy": 1.0,
    "mmlu_redux_professional_accounting": 1.0,
    "mmlu_redux_professional_law": 1.0,
    "mmlu_redux_public_relations": 1.0,
    "mmlu_redux_virology": 1.0
  },
  "n-shot": {
    "mmlu_redux_anatomy": 5,
    "mmlu_redux_astronomy": 5,
    "mmlu_redux_business_ethics": 5,
    "mmlu_redux_clinical_knowledge": 5,
    "mmlu_redux_college_chemistry": 5,
    "mmlu_redux_college_computer_science": 5,
    "mmlu_redux_college_mathematics": 5,
    "mmlu_redux_college_medicine": 5,
    "mmlu_redux_college_physics": 5,
    "mmlu_redux_conceptual_physics": 5,
    "mmlu_redux_econometrics": 5,
    "mmlu_redux_electrical_engineering": 5,
    "mmlu_redux_formal_logic": 5,
    "mmlu_redux_global_facts": 5,
    "mmlu_redux_high_school_chemistry": 5,
    "mmlu_redux_high_school_geography": 5,
    "mmlu_redux_high_school_macroeconomics": 5,
    "mmlu_redux_high_school_mathematics": 5,
    "mmlu_redux_high_school_physics": 5,
    "mmlu_redux_high_school_statistics": 5,
    "mmlu_redux_high_school_us_history": 5,
    "mmlu_redux_human_aging": 5,
    "mmlu_redux_logical_fallacies": 5,
    "mmlu_redux_machine_learning": 5,
    "mmlu_redux_miscellaneous": 5,
    "mmlu_redux_philosophy": 5,
    "mmlu_redux_professional_accounting": 5,
    "mmlu_redux_professional_law": 5,
    "mmlu_redux_public_relations": 5,
    "mmlu_redux_virology": 5
  },
  "higher_is_better": {
    "mmlu_redux": {
      "acc": true
    },
    "mmlu_redux_anatomy": {
      "acc": true
    },
    "mmlu_redux_astronomy": {
      "acc": true
    },
    "mmlu_redux_business_ethics": {
      "acc": true
    },
    "mmlu_redux_clinical_knowledge": {
      "acc": true
    },
    "mmlu_redux_college_chemistry": {
      "acc": true
    },
    "mmlu_redux_college_computer_science": {
      "acc": true
    },
    "mmlu_redux_college_mathematics": {
      "acc": true
    },
    "mmlu_redux_college_medicine": {
      "acc": true
    },
    "mmlu_redux_college_physics": {
      "acc": true
    },
    "mmlu_redux_conceptual_physics": {
      "acc": true
    },
    "mmlu_redux_econometrics": {
      "acc": true
    },
    "mmlu_redux_electrical_engineering": {
      "acc": true
    },
    "mmlu_redux_formal_logic": {
      "acc": true
    },
    "mmlu_redux_global_facts": {
      "acc": true
    },
    "mmlu_redux_high_school_chemistry": {
      "acc": true
    },
    "mmlu_redux_high_school_geography": {
      "acc": true
    },
    "mmlu_redux_high_school_macroeconomics": {
      "acc": true
    },
    "mmlu_redux_high_school_mathematics": {
      "acc": true
    },
    "mmlu_redux_high_school_physics": {
      "acc": true
    },
    "mmlu_redux_high_school_statistics": {
      "acc": true
    },
    "mmlu_redux_high_school_us_history": {
      "acc": true
    },
    "mmlu_redux_human_aging": {
      "acc": true
    },
    "mmlu_redux_logical_fallacies": {
      "acc": true
    },
    "mmlu_redux_machine_learning": {
      "acc": true
    },
    "mmlu_redux_miscellaneous": {
      "acc": true
    },
    "mmlu_redux_philosophy": {
      "acc": true
    },
    "mmlu_redux_professional_accounting": {
      "acc": true
    },
    "mmlu_redux_professional_law": {
      "acc": true
    },
    "mmlu_redux_public_relations": {
      "acc": true
    },
    "mmlu_redux_virology": {
      "acc": true
    }
  },
  "n-samples": {
    "mmlu_redux_machine_learning": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_professional_law": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_logical_fallacies": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_high_school_macroeconomics": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_conceptual_physics": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_human_aging": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_philosophy": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_virology": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_clinical_knowledge": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_college_chemistry": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_astronomy": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_public_relations": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_miscellaneous": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_college_medicine": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_high_school_mathematics": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_high_school_physics": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_anatomy": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_global_facts": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_high_school_statistics": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_high_school_us_history": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_high_school_chemistry": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_college_computer_science": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_econometrics": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_high_school_geography": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_professional_accounting": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_business_ethics": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_formal_logic": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_college_mathematics": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_electrical_engineering": {
      "original": 100,
      "effective": 100
    },
    "mmlu_redux_college_physics": {
      "original": 100,
      "effective": 100
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=deepseek-ai/DeepSeek-R1-Distill-Qwen-7B,parallelize=True,attn_implementation=sdpa",
    "model_num_parameters": 7615616512,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "393119fcd6a873e5776c79b0db01c96911f5f0fc",
    "batch_size": 1,
    "batch_sizes": [],
    "device": "cuda",
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "f0bcb72",
  "date": 1737868828.4544797,
  "pretty_env_info": "PyTorch version: 2.5.1+cu124\nIs debug build: False\nCUDA used to build PyTorch: 12.4\nROCM used to build PyTorch: N/A\n\nOS: Rocky Linux 8.4 (Green Obsidian) (x86_64)\nGCC version: (GCC) 8.5.0 20210514 (Red Hat 8.5.0-4)\nClang version: Could not collect\nCMake version: Could not collect\nLibc version: glibc-2.28\n\nPython version: 3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0] (64-bit runtime)\nPython platform: Linux-4.18.0-305.19.1.el8_4.x86_64-x86_64-with-glibc2.28\nIs CUDA available: True\nCUDA runtime version: Could not collect\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: \nGPU 0: NVIDIA A100-SXM4-80GB\nGPU 1: NVIDIA A100-SXM4-80GB\nGPU 2: NVIDIA A100-SXM4-80GB\nGPU 3: NVIDIA A100-SXM4-80GB\n\nNvidia driver version: 535.104.12\ncuDNN version: Probably one of the following:\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_adv_train.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8.2.1\n/usr/local/cuda-11.3/targets/x86_64-linux/lib/libcudnn_ops_train.so.8.2.1\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nCPU(s):              128\nOn-line CPU(s) list: 0-127\nThread(s) per core:  2\nCore(s) per socket:  32\nSocket(s):           2\nNUMA node(s):        2\nVendor ID:           AuthenticAMD\nCPU family:          25\nModel:               1\nModel name:          AMD EPYC 7513 32-Core Processor\nStepping:            1\nCPU MHz:             3494.511\nCPU max MHz:         2600.0000\nCPU min MHz:         1500.0000\nBogoMIPS:            5190.38\nVirtualization:      AMD-V\nL1d cache:           32K\nL1i cache:           32K\nL2 cache:            512K\nL3 cache:            32768K\nNUMA node0 CPU(s):   0-31,64-95\nNUMA node1 CPU(s):   32-63,96-127\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 invpcid_single hw_pstate sme ssbd mba sev ibrs ibpb stibp vmmcall sev_es fsgsbase bmi1 avx2 smep bmi2 erms invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd amd_ppin arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload vgif umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca fsrm\n\nVersions of relevant libraries:\n[pip3] numpy==2.1.3\n[pip3] torch==2.5.1\n[pip3] triton==3.1.0\n[conda] numpy                     1.26.4                   pypi_0    pypi\n[conda] optree                    0.11.0                   pypi_0    pypi\n[conda] torch                     2.4.1                    pypi_0    pypi\n[conda] torchvision               0.19.1                   pypi_0    pypi\n[conda] triton                    3.0.0                    pypi_0    pypi",
  "transformers_version": "4.46.2",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<｜end▁of▁sentence｜>",
    "151643"
  ],
  "tokenizer_eos_token": [
    "<｜end▁of▁sentence｜>",
    "151643"
  ],
  "tokenizer_bos_token": [
    "<｜begin▁of▁sentence｜>",
    "151646"
  ],
  "eot_token_id": 151643,
  "max_length": 131072,
  "task_hashes": {
    "mmlu_redux_machine_learning": "825acd9c778edf0d75733399fce44c327b18171e4d4f5888628473aeff6a0d7c",
    "mmlu_redux_professional_law": "8555d67f4e3b72282215317d2ddcae7344335fe8c574fa656b834228dc49ac7a",
    "mmlu_redux_logical_fallacies": "4c1073ea3cf7cbb1eb3445189fe79260b3fed39b254ebccb21667e40a0ad83dc",
    "mmlu_redux_high_school_macroeconomics": "cfac3c2b906eb4d803d3dad1f811b2eaaa0b8151952e74917be4cfc43b5f881f",
    "mmlu_redux_conceptual_physics": "b831f19d765a3bc000ab975064e5325908ea40281fed58b729902ed201af8d05",
    "mmlu_redux_human_aging": "17f5a392c4a84b78b984414a8a231ef112b7c03439eb9f06614d5b8eb20752a6",
    "mmlu_redux_philosophy": "4ffe690a52baf8f440ec49109a38faea4513ff45359af3014fefc94ec47f1ecd",
    "mmlu_redux_virology": "3718f6b255575e0107bb0a679ec367a7f7becf688ba2f1ad8d68ee1447082ee9",
    "mmlu_redux_clinical_knowledge": "fb4467033a4403910b2255fc85d4ef125c749a34cac42b45971b45bde8d66d3c",
    "mmlu_redux_college_chemistry": "49aa55765a6ef56a79ff63adae4dc16b226a42674ec2ea0e678264c5a5037669",
    "mmlu_redux_astronomy": "1e904ae79475d4008018b4c8faf679bc481914bd7e1f6cec55f2a4541a1330de",
    "mmlu_redux_public_relations": "cdc51b10403b5de14f8787c4d4c7c03e914bdb9189cd1b9d572cffc28438bc42",
    "mmlu_redux_miscellaneous": "3d04903d36c5b2b4b9978a6c4b4077111c31031a463b28231cfd9f47ac05b5d2",
    "mmlu_redux_college_medicine": "5fb73ae9e11ec511c5f2bbc136445e64d0e551c4cf9eca1ce4c2a3823542a8d9",
    "mmlu_redux_high_school_mathematics": "bcac471b2dba5018c39b474729f101c806eb9a0ecf11482ed4b915ce10f4249a",
    "mmlu_redux_high_school_physics": "c1f2fd7508710d2bbfc662386ebae02fbf3aed3651e3b174f019bebc27b60ece",
    "mmlu_redux_anatomy": "3aa2953fd3e9e9eff620988f32bcff52062cf208f1307c9d0d3c58511c510c46",
    "mmlu_redux_global_facts": "9189f621dc81beaf384131480e726e93aa6328ad487d15ad82ea75eb00769c78",
    "mmlu_redux_high_school_statistics": "6211bd1ab6eb6ca4318239c310ffabf7d02e097ae876c816dce041a270414517",
    "mmlu_redux_high_school_us_history": "f6be3d6e77ce33315f70692bd13642006fa134ffabb8a0ebeaab6d38d4e6cf30",
    "mmlu_redux_high_school_chemistry": "adc899fcc53b73295c315686a5bd5135ea08e1fa7d3cffb0181498d5dd33a15a",
    "mmlu_redux_college_computer_science": "103f3e7fad8fc2c65ad0ee157e5bda67e656c300a3e4b23054c526389770edae",
    "mmlu_redux_econometrics": "3c36d90da997054eeb32aab472970c3824eada88557bc52f8618f05ff6e060eb",
    "mmlu_redux_high_school_geography": "b120319f7fadf7ac9565bd53e0e13cd2f7e767232deff3883bcadd8d6d449df1",
    "mmlu_redux_professional_accounting": "5e4cf3dee5ac80a3304b2f150dd59b9d37920dc9b14dcffe6bdfc2586c26cf4a",
    "mmlu_redux_business_ethics": "5e7bb5d4b6cfb3334abd036d28dad3957a893d448a3992e40e42f81d78ec2b69",
    "mmlu_redux_formal_logic": "7002e110f1b9b980795593624b02ddd4d2b19965ff3457d598cd7db9f3f3cfdf",
    "mmlu_redux_college_mathematics": "1c4897eff38adc57980521cb1807572371aea2d6866f7580cc36ae7862815cfd",
    "mmlu_redux_electrical_engineering": "bc08e7fb5c8cd389e07869d79bca4988036ac436f7c2a7d110bef02bc641ed55",
    "mmlu_redux_college_physics": "bd2e7c2dc72fa78cba00af661cb47612bddb9597d08b2b5b0fa4a55cd9f17937"
  },
  "model_source": "hf",
  "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
  "model_name_sanitized": "deepseek-ai__DeepSeek-R1-Distill-Qwen-7B",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 11105897.792188792,
  "end_time": 11106570.38488646,
  "total_evaluation_time_seconds": "672.5926976688206"
}